{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "from jax.scipy.linalg import expm\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "import qutip as qu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 0.3\n",
    "c_ops = [J * qu.sigmax()]\n",
    "\n",
    "H0 = 0.2*qu.sigmax()\n",
    "psi0 = qu.basis(2, 0)\n",
    "rho0 = qu.ket2dm(psi0)\n",
    "\n",
    "projs = [np.array([[1, 0], [0, 0]]), np.array([[0, 0], [0, 1]])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def evolve_dm(rho0, H0, operators, t, no_qubits=1):\n",
    "    liouvillian = qu.liouvillian(H0, c_ops=operators)\n",
    "    rho_sup = qu.to_super(rho0)\n",
    "    rho_evol = scipy.linalg.expm(liouvillian.full()*t)@rho_sup.full()\n",
    "    dm_evol = rho_evol[:, 0].reshape(-1, 2**no_qubits)\n",
    "    dm_evol = qu.Qobj(dm_evol)\n",
    "    return dm_evol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def partial_rho_gamma(rho0, H0, operators, t, bare_jump_op, no_qubits=1):\n",
    "    liouvillian = qu.liouvillian(H0, c_ops=operators)\n",
    "    dissipator = qu.lindblad_dissipator(bare_jump_op)\n",
    "\n",
    "    print(dissipator)\n",
    "    rho_sup = qu.to_super(rho0)\n",
    "    rho_evol = (\n",
    "        \n",
    "            t*scipy.linalg.expm(liouvillian.full() * t) @ dissipator.full()  @rho_sup.full() \n",
    "       \n",
    "        \n",
    "    )\n",
    "    # print(rho_evol)\n",
    "    dm_evol = rho_evol[:, 0].reshape(-1, 2**no_qubits)\n",
    "    print(dm_evol)\n",
    "    dm_evol = qu.Qobj(dm_evol)\n",
    "    return dm_evol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_evol_super(H0, ops):\n",
    "    return (qu.liouvillian(H0, c_ops=ops) - qu.lindblad_dissipator(ops)).full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = qu.lindblad_dissipator(qu.sigmax()).full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = make_evol_super(H0, qu.sigmax())\n",
    "\n",
    "C = qu.to_super(rho0).full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.8\n",
    "\n",
    "def evol(gamma, A, B, C):\n",
    "    d = qu.basis(2, 0).full()\n",
    "    return jnp.real(jnp.trace(projs[1]@(expm(A + gamma*B)@C)[:, 0].reshape(-1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_dm(rho0, H0, operators, t, no_qubits=1):\n",
    "    liouvillian = qu.liouvillian(H0, c_ops=operators)\n",
    "    rho_sup = qu.to_super(rho0)\n",
    "    rho_evol = expm(liouvillian.full()*t)@rho_sup.full()\n",
    "    dm_evol = rho_evol[:, 0].reshape(-1, 2**no_qubits)\n",
    "    # dm_evol = qu.Qobj(dm_evol)\n",
    "    return dm_evol\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Gradient only defined for scalar-output functions. Output had shape: (2, 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/antonio/dev/simple-QLL/jax.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/antonio/dev/simple-QLL/jax.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grad(evolve_dm, \u001b[39m3\u001b[39;49m)(rho0, H0, qu\u001b[39m.\u001b[39;49msigmax(), \u001b[39m0.3\u001b[39;49m)\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/qinfer/lib/python3.10/site-packages/jax/_src/api.py:1174\u001b[0m, in \u001b[0;36m_check_scalar\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(aval, ShapedArray):\n\u001b[1;32m   1173\u001b[0m   \u001b[39mif\u001b[39;00m aval\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m ():\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhad shape: \u001b[39m\u001b[39m{\u001b[39;00maval\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhad abstract value \u001b[39m\u001b[39m{\u001b[39;00maval\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Gradient only defined for scalar-output functions. Output had shape: (2, 2)."
     ]
    }
   ],
   "source": [
    "grad(evolve_dm, 3)(rho0, H0, qu.sigmax(), 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(8.940697e-08, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(evol, 0)(9., A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.08 ms ± 419 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "long_vector = jnp.array([jnp.arange(int(1e8)) for _ in range(2)])\n",
    "\n",
    "%timeit jnp.dot(np.sum(long_vector), np.sum(long_vector)).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 ms ± 5.81 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "long_vector = np.array([np.arange(int(1e8)) for _ in range(2)])\n",
    "\n",
    "%timeit np.dot(np.sum(long_vector), np.sum(long_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamExecutorGpuDevice(id=0, process_index=0)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0min_axes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Union[int, Sequence[Any]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mout_axes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Hashable]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maxis_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mspmd_axis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Hashable]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Vectorizing map. Creates a function which maps ``fun`` over argument axes.\n",
      "\n",
      "Args:\n",
      "  fun: Function to be mapped over additional axes.\n",
      "  in_axes: An integer, None, or (nested) standard Python container\n",
      "    (tuple/list/dict) thereof specifying which input array axes to map over.\n",
      "\n",
      "    If each positional argument to ``fun`` is an array, then ``in_axes`` can\n",
      "    be an integer, a None, or a tuple of integers and Nones with length equal\n",
      "    to the number of positional arguments to ``fun``. An integer or ``None``\n",
      "    indicates which array axis to map over for all arguments (with ``None``\n",
      "    indicating not to map any axis), and a tuple indicates which axis to map\n",
      "    for each corresponding positional argument. Axis integers must be in the\n",
      "    range ``[-ndim, ndim)`` for each array, where ``ndim`` is the number of\n",
      "    dimensions (axes) of the corresponding input array.\n",
      "\n",
      "    If the positional arguments to ``fun`` are container (pytree) types, the\n",
      "    corresponding element of ``in_axes`` can itself be a matching container,\n",
      "    so that distinct array axes can be mapped for different container\n",
      "    elements. ``in_axes`` must be a container tree prefix of the positional\n",
      "    argument tuple passed to ``fun``. See this link for more detail:\n",
      "    https://jax.readthedocs.io/en/latest/pytrees.html#applying-optional-parameters-to-pytrees\n",
      "\n",
      "    Either ``axis_size`` must be provided explicitly, or at least one\n",
      "    positional argument must have ``in_axes`` not None. The sizes of the\n",
      "    mapped input axes for all mapped positional arguments must all be equal.\n",
      "\n",
      "    Arguments passed as keywords are always mapped over their leading axis\n",
      "    (i.e. axis index 0).\n",
      "\n",
      "    See below for examples.\n",
      "\n",
      "  out_axes: An integer, None, or (nested) standard Python container\n",
      "    (tuple/list/dict) thereof indicating where the mapped axis should appear\n",
      "    in the output. All outputs with a mapped axis must have a non-None\n",
      "    ``out_axes`` specification. Axis integers must be in the range ``[-ndim,\n",
      "    ndim)`` for each output array, where ``ndim`` is the number of dimensions\n",
      "    (axes) of the array returned by the :func:`vmap`-ed function, which is one\n",
      "    more than the number of dimensions (axes) of the corresponding array\n",
      "    returned by ``fun``.\n",
      "  axis_name: Optional, a hashable Python object used to identify the mapped\n",
      "    axis so that parallel collectives can be applied.\n",
      "  axis_size: Optional, an integer indicating the size of the axis to be\n",
      "    mapped. If not provided, the mapped axis size is inferred from arguments.\n",
      "\n",
      "Returns:\n",
      "  Batched/vectorized version of ``fun`` with arguments that correspond to\n",
      "  those of ``fun``, but with extra array axes at positions indicated by\n",
      "  ``in_axes``, and a return value that corresponds to that of ``fun``, but\n",
      "  with extra array axes at positions indicated by ``out_axes``.\n",
      "\n",
      "For example, we can implement a matrix-matrix product using a vector dot\n",
      "product:\n",
      "\n",
      ">>> import jax.numpy as jnp\n",
      ">>>\n",
      ">>> vv = lambda x, y: jnp.vdot(x, y)  #  ([a], [a]) -> []\n",
      ">>> mv = vmap(vv, (0, None), 0)      #  ([b,a], [a]) -> [b]      (b is the mapped axis)\n",
      ">>> mm = vmap(mv, (None, 1), 1)      #  ([b,a], [a,c]) -> [b,c]  (c is the mapped axis)\n",
      "\n",
      "Here we use ``[a,b]`` to indicate an array with shape (a,b). Here are some\n",
      "variants:\n",
      "\n",
      ">>> mv1 = vmap(vv, (0, 0), 0)   #  ([b,a], [b,a]) -> [b]        (b is the mapped axis)\n",
      ">>> mv2 = vmap(vv, (0, 1), 0)   #  ([b,a], [a,b]) -> [b]        (b is the mapped axis)\n",
      ">>> mm2 = vmap(mv2, (1, 1), 0)  #  ([b,c,a], [a,c,b]) -> [c,b]  (c is the mapped axis)\n",
      "\n",
      "Here's an example of using container types in ``in_axes`` to specify which\n",
      "axes of the container elements to map over:\n",
      "\n",
      ">>> A, B, C, D = 2, 3, 4, 5\n",
      ">>> x = jnp.ones((A, B))\n",
      ">>> y = jnp.ones((B, C))\n",
      ">>> z = jnp.ones((C, D))\n",
      ">>> def foo(tree_arg):\n",
      "...   x, (y, z) = tree_arg\n",
      "...   return jnp.dot(x, jnp.dot(y, z))\n",
      ">>> tree = (x, (y, z))\n",
      ">>> print(foo(tree))\n",
      "[[12. 12. 12. 12. 12.]\n",
      " [12. 12. 12. 12. 12.]]\n",
      ">>> from jax import vmap\n",
      ">>> K = 6  # batch size\n",
      ">>> x = jnp.ones((K, A, B))  # batch axis in different locations\n",
      ">>> y = jnp.ones((B, K, C))\n",
      ">>> z = jnp.ones((C, D, K))\n",
      ">>> tree = (x, (y, z))\n",
      ">>> vfoo = vmap(foo, in_axes=((0, (1, 2)),))\n",
      ">>> print(vfoo(tree).shape)\n",
      "(6, 2, 5)\n",
      "\n",
      "Here's another example using container types in ``in_axes``, this time a\n",
      "dictionary, to specify the elements of the container to map over:\n",
      "\n",
      ">>> dct = {'a': 0., 'b': jnp.arange(5.)}\n",
      ">>> x = 1.\n",
      ">>> def foo(dct, x):\n",
      "...  return dct['a'] + dct['b'] + x\n",
      ">>> out = vmap(foo, in_axes=({'a': None, 'b': 0}, None))(dct, x)\n",
      ">>> print(out)\n",
      "[1. 2. 3. 4. 5.]\n",
      "\n",
      "The results of a vectorized function can be mapped or unmapped. For example,\n",
      "the function below returns a pair with the first element mapped and the second\n",
      "unmapped. Only for unmapped results we can specify ``out_axes`` to be ``None``\n",
      "(to keep it unmapped).\n",
      "\n",
      ">>> print(vmap(lambda x, y: (x + y, y * 2.), in_axes=(0, None), out_axes=(0, None))(jnp.arange(2.), 4.))\n",
      "(DeviceArray([4., 5.], dtype=float32), 8.0)\n",
      "\n",
      "If the ``out_axes`` is specified for an unmapped result, the result is\n",
      "broadcast across the mapped axis:\n",
      "\n",
      ">>> print(vmap(lambda x, y: (x + y, y * 2.), in_axes=(0, None), out_axes=0)(jnp.arange(2.), 4.))\n",
      "(DeviceArray([4., 5.], dtype=float32), DeviceArray([8., 8.], dtype=float32, weak_type=True))\n",
      "\n",
      "If the ``out_axes`` is specified for a mapped result, the result is transposed\n",
      "accordingly.\n",
      "\n",
      "Finally, here's an example using ``axis_name`` together with collectives:\n",
      "\n",
      ">>> xs = jnp.arange(3. * 4.).reshape(3, 4)\n",
      ">>> print(vmap(lambda x: lax.psum(x, 'i'), axis_name='i')(xs))\n",
      "[[12. 15. 18. 21.]\n",
      " [12. 15. 18. 21.]\n",
      " [12. 15. 18. 21.]]\n",
      "\n",
      "See the :py:func:`jax.pmap` docstring for more examples involving collectives.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/qinfer/lib/python3.10/site-packages/jax/_src/api.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "# ?jax.vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_models import simple_precession_with_noise\n",
    "\n",
    "n = simple_precession_with_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'simple_precession_with_noise' object has no attribute 'measurement_projectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/antonio/dev/simple-QLL/jax.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/antonio/dev/simple-QLL/jax.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n\u001b[39m.\u001b[39;49mmeasurement_projectors\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'simple_precession_with_noise' object has no attribute 'measurement_projectors'"
     ]
    }
   ],
   "source": [
    "n.measurement_projectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('qinfer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7be0bd88622506fe35bac977978794a21d34eb3b6bd5d6506b9cc4f370666d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
